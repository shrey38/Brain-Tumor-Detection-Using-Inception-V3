{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4bc7581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.21.5)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (3.5.1)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from seaborn) (1.7.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.11.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (21.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.4.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (4.31.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (9.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shreeyash pandey\\uh\\envs\\new\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=2.2->seaborn) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import keras \n",
    "!pip install seaborn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fd7a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = OneHotEncoder()\n",
    "encoder.fit([[0], [1]]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "886b6016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "paths = []\n",
    "result = []\n",
    "\n",
    "for r, d, f in os.walk(r'C:\\Users\\Shreeyash Pandey\\Downloads\\archive (3)\\DataSet\\yes'):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[0]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774ec888",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = []\n",
    "for r, d, f in os.walk(r\"C:\\Users\\Shreeyash Pandey\\Downloads\\archive (3)\\DataSet\\no\"):\n",
    "    for file in f:\n",
    "        if '.jpg' in file:\n",
    "            paths.append(os.path.join(r, file))\n",
    "\n",
    "for path in paths:\n",
    "    img = Image.open(path)\n",
    "    img = img.resize((128,128))\n",
    "    img = np.array(img)\n",
    "    if(img.shape == (128,128,3)):\n",
    "        data.append(np.array(img))\n",
    "        result.append(encoder.transform([[1]]).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "829683ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2594, 128, 128, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array(data)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b433498d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.array(result)\n",
    "result = result.reshape(2594,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "023a235e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(data, result, test_size=0.2, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6fb578af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.applications.inception_v3 import decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ab9f836",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InceptionV3(input_shape=(128,128,3),weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6dafa068",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0d261cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "\n",
    "predictions = Dense(2, activation='sigmoid')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da65e8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  5,   5,   5],\n",
       "         [ 13,  13,  13],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  6,   6,   6],\n",
       "         [  8,   8,   8],\n",
       "         [  6,   6,   6]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [ 15,  15,  15],\n",
       "         [ 10,  10,  10],\n",
       "         [ 11,  11,  11]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  9,   9,   9],\n",
       "         [ 19,  19,  19],\n",
       "         [ 18,  18,  18]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [ 10,  10,  10],\n",
       "         [ 12,  12,  12],\n",
       "         [ 10,  10,  10]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  9,   9,   9],\n",
       "         [ 14,  14,  14],\n",
       "         [ 14,  14,  14]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]],\n",
       "\n",
       "\n",
       "       [[[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[151, 153, 152],\n",
       "         [ 59,  61,  60],\n",
       "         [ 49,  51,  50],\n",
       "         ...,\n",
       "         [ 60,  62,  61],\n",
       "         [ 55,  57,  56],\n",
       "         [ 43,  45,  44]],\n",
       "\n",
       "        [[145, 146, 146],\n",
       "         [ 89,  90,  89],\n",
       "         [ 48,  50,  49],\n",
       "         ...,\n",
       "         [ 61,  63,  62],\n",
       "         [ 52,  54,  53],\n",
       "         [ 42,  44,  43]],\n",
       "\n",
       "        [[144, 145, 145],\n",
       "         [ 84,  86,  85],\n",
       "         [ 50,  52,  51],\n",
       "         ...,\n",
       "         [ 62,  64,  63],\n",
       "         [ 53,  55,  54],\n",
       "         [ 46,  48,  47]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[144, 144, 144],\n",
       "         [ 91,  91,  91],\n",
       "         [ 58,  58,  58],\n",
       "         ...,\n",
       "         [ 48,  48,  48],\n",
       "         [ 46,  46,  46],\n",
       "         [ 46,  46,  46]],\n",
       "\n",
       "        [[145, 145, 145],\n",
       "         [ 88,  88,  88],\n",
       "         [ 62,  62,  62],\n",
       "         ...,\n",
       "         [ 45,  45,  45],\n",
       "         [ 44,  44,  44],\n",
       "         [ 39,  39,  39]],\n",
       "\n",
       "        [[149, 149, 149],\n",
       "         [ 67,  67,  67],\n",
       "         [ 72,  72,  72],\n",
       "         ...,\n",
       "         [ 54,  54,  54],\n",
       "         [ 74,  74,  74],\n",
       "         [ 39,  39,  39]]],\n",
       "\n",
       "\n",
       "       [[[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  2,   2,   2]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1],\n",
       "         [  1,   1,   1]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]],\n",
       "\n",
       "        [[  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0]]],\n",
       "\n",
       "\n",
       "       [[[133, 133, 133],\n",
       "         [119, 119, 119],\n",
       "         [120, 120, 120],\n",
       "         ...,\n",
       "         [123, 123, 123],\n",
       "         [140, 140, 140],\n",
       "         [241, 241, 241]],\n",
       "\n",
       "        [[  3,   3,   3],\n",
       "         [  0,   0,   0],\n",
       "         [  0,   0,   0],\n",
       "         ...,\n",
       "         [  7,   7,   7],\n",
       "         [ 48,  48,  48],\n",
       "         [241, 241, 241]],\n",
       "\n",
       "        [[ 23,  23,  23],\n",
       "         [ 17,  17,  17],\n",
       "         [ 16,  16,  16],\n",
       "         ...,\n",
       "         [ 31,  31,  31],\n",
       "         [ 65,  65,  65],\n",
       "         [240, 240, 240]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[  9,   9,   9],\n",
       "         [ 10,  10,  10],\n",
       "         [  7,   7,   7],\n",
       "         ...,\n",
       "         [  2,   2,   2],\n",
       "         [ 33,  33,  33],\n",
       "         [244, 244, 244]],\n",
       "\n",
       "        [[ 14,  14,  14],\n",
       "         [  4,   4,   4],\n",
       "         [  3,   3,   3],\n",
       "         ...,\n",
       "         [  1,   1,   1],\n",
       "         [ 35,  35,  35],\n",
       "         [245, 245, 245]],\n",
       "\n",
       "        [[ 25,  25,  25],\n",
       "         [  5,   5,   5],\n",
       "         [  5,   5,   5],\n",
       "         ...,\n",
       "         [  5,   5,   5],\n",
       "         [ 39,  39,  39],\n",
       "         [245, 245, 245]]]], dtype=uint8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c6dafc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "208/208 [==============================] - 61s 295ms/step - loss: 0.4325 - accuracy: 0.9214 - val_loss: 0.4560 - val_accuracy: 0.9133\n",
      "Epoch 2/50\n",
      "208/208 [==============================] - 62s 298ms/step - loss: 0.4846 - accuracy: 0.9176 - val_loss: 0.8440 - val_accuracy: 0.8709\n",
      "Epoch 3/50\n",
      "208/208 [==============================] - 71s 342ms/step - loss: 0.4750 - accuracy: 0.9258 - val_loss: 2.0432 - val_accuracy: 0.8189\n",
      "Epoch 4/50\n",
      "208/208 [==============================] - 75s 363ms/step - loss: 0.4693 - accuracy: 0.9258 - val_loss: 1.4807 - val_accuracy: 0.8189\n",
      "Epoch 5/50\n",
      "208/208 [==============================] - 65s 310ms/step - loss: 0.5697 - accuracy: 0.9253 - val_loss: 1.0420 - val_accuracy: 0.8805\n",
      "Epoch 6/50\n",
      "208/208 [==============================] - 65s 314ms/step - loss: 0.4371 - accuracy: 0.9378 - val_loss: 0.5085 - val_accuracy: 0.9171\n",
      "Epoch 7/50\n",
      "208/208 [==============================] - 63s 305ms/step - loss: 0.3453 - accuracy: 0.9494 - val_loss: 0.8286 - val_accuracy: 0.9056\n",
      "Epoch 8/50\n",
      "208/208 [==============================] - 64s 310ms/step - loss: 0.4085 - accuracy: 0.9407 - val_loss: 0.6124 - val_accuracy: 0.9326\n",
      "Epoch 9/50\n",
      "208/208 [==============================] - 66s 320ms/step - loss: 0.4017 - accuracy: 0.9431 - val_loss: 0.4098 - val_accuracy: 0.9441\n",
      "Epoch 10/50\n",
      "208/208 [==============================] - 71s 342ms/step - loss: 0.3231 - accuracy: 0.9508 - val_loss: 0.7973 - val_accuracy: 0.9210\n",
      "Epoch 11/50\n",
      "208/208 [==============================] - 68s 327ms/step - loss: 0.2942 - accuracy: 0.9639 - val_loss: 0.5637 - val_accuracy: 0.9268\n",
      "Epoch 12/50\n",
      "208/208 [==============================] - 68s 326ms/step - loss: 0.3908 - accuracy: 0.9566 - val_loss: 0.8021 - val_accuracy: 0.9268\n",
      "Epoch 13/50\n",
      "208/208 [==============================] - 70s 337ms/step - loss: 0.2932 - accuracy: 0.9619 - val_loss: 0.6370 - val_accuracy: 0.9364\n",
      "Epoch 14/50\n",
      "208/208 [==============================] - 65s 315ms/step - loss: 0.2859 - accuracy: 0.9581 - val_loss: 0.7904 - val_accuracy: 0.9403\n",
      "Epoch 15/50\n",
      "208/208 [==============================] - 71s 343ms/step - loss: 0.4009 - accuracy: 0.9513 - val_loss: 0.6218 - val_accuracy: 0.9306\n",
      "Epoch 16/50\n",
      "208/208 [==============================] - 64s 306ms/step - loss: 0.2667 - accuracy: 0.9634 - val_loss: 1.7233 - val_accuracy: 0.8825\n",
      "Epoch 17/50\n",
      "208/208 [==============================] - 64s 310ms/step - loss: 0.2203 - accuracy: 0.9667 - val_loss: 1.0962 - val_accuracy: 0.9191\n",
      "Epoch 18/50\n",
      "208/208 [==============================] - 66s 319ms/step - loss: 0.2674 - accuracy: 0.9701 - val_loss: 0.8986 - val_accuracy: 0.9403\n",
      "Epoch 19/50\n",
      "208/208 [==============================] - 66s 320ms/step - loss: 0.3016 - accuracy: 0.9696 - val_loss: 1.0862 - val_accuracy: 0.9171\n",
      "Epoch 20/50\n",
      "208/208 [==============================] - 63s 302ms/step - loss: 0.2237 - accuracy: 0.9735 - val_loss: 0.9215 - val_accuracy: 0.9383\n",
      "Epoch 21/50\n",
      "208/208 [==============================] - 68s 325ms/step - loss: 0.1595 - accuracy: 0.9706 - val_loss: 2.3546 - val_accuracy: 0.8690\n",
      "Epoch 22/50\n",
      "208/208 [==============================] - 88s 426ms/step - loss: 0.3673 - accuracy: 0.9653 - val_loss: 1.4976 - val_accuracy: 0.9268\n",
      "Epoch 23/50\n",
      "208/208 [==============================] - 86s 415ms/step - loss: 0.2642 - accuracy: 0.9701 - val_loss: 1.0773 - val_accuracy: 0.9152\n",
      "Epoch 24/50\n",
      "208/208 [==============================] - 80s 387ms/step - loss: 0.3180 - accuracy: 0.9672 - val_loss: 1.3014 - val_accuracy: 0.9210\n",
      "Epoch 25/50\n",
      "208/208 [==============================] - 66s 320ms/step - loss: 0.2813 - accuracy: 0.9692 - val_loss: 1.2553 - val_accuracy: 0.9191\n",
      "Epoch 26/50\n",
      "208/208 [==============================] - 66s 315ms/step - loss: 0.4381 - accuracy: 0.9614 - val_loss: 1.2495 - val_accuracy: 0.9364\n",
      "Epoch 27/50\n",
      "208/208 [==============================] - 66s 316ms/step - loss: 0.4971 - accuracy: 0.9682 - val_loss: 0.8634 - val_accuracy: 0.9403\n",
      "Epoch 28/50\n",
      "208/208 [==============================] - 66s 318ms/step - loss: 0.2550 - accuracy: 0.9773 - val_loss: 0.8864 - val_accuracy: 0.9345\n",
      "Epoch 29/50\n",
      "208/208 [==============================] - 69s 331ms/step - loss: 0.1114 - accuracy: 0.9870 - val_loss: 1.0784 - val_accuracy: 0.9441\n",
      "Epoch 30/50\n",
      "208/208 [==============================] - 74s 357ms/step - loss: 0.2547 - accuracy: 0.9749 - val_loss: 1.2769 - val_accuracy: 0.9306\n",
      "Epoch 31/50\n",
      "208/208 [==============================] - 71s 341ms/step - loss: 0.3102 - accuracy: 0.9769 - val_loss: 1.3166 - val_accuracy: 0.9461\n",
      "Epoch 32/50\n",
      "208/208 [==============================] - 62s 300ms/step - loss: 0.2364 - accuracy: 0.9778 - val_loss: 1.3835 - val_accuracy: 0.9461\n",
      "Epoch 33/50\n",
      "208/208 [==============================] - 59s 282ms/step - loss: 0.1911 - accuracy: 0.9836 - val_loss: 1.3214 - val_accuracy: 0.9383\n",
      "Epoch 34/50\n",
      "208/208 [==============================] - 59s 282ms/step - loss: 0.1987 - accuracy: 0.9827 - val_loss: 1.2248 - val_accuracy: 0.9461\n",
      "Epoch 35/50\n",
      "208/208 [==============================] - 69s 332ms/step - loss: 0.2480 - accuracy: 0.9831 - val_loss: 1.5198 - val_accuracy: 0.9326\n",
      "Epoch 36/50\n",
      "208/208 [==============================] - 58s 281ms/step - loss: 0.1652 - accuracy: 0.9851 - val_loss: 1.1976 - val_accuracy: 0.9345\n",
      "Epoch 37/50\n",
      "208/208 [==============================] - 66s 320ms/step - loss: 0.2046 - accuracy: 0.9827 - val_loss: 1.8386 - val_accuracy: 0.9268\n",
      "Epoch 38/50\n",
      "208/208 [==============================] - 72s 348ms/step - loss: 0.1872 - accuracy: 0.9827 - val_loss: 1.1313 - val_accuracy: 0.9422\n",
      "Epoch 39/50\n",
      "208/208 [==============================] - 76s 366ms/step - loss: 0.1405 - accuracy: 0.9841 - val_loss: 1.5957 - val_accuracy: 0.9383\n",
      "Epoch 40/50\n",
      "208/208 [==============================] - 67s 322ms/step - loss: 0.1193 - accuracy: 0.9933 - val_loss: 1.9332 - val_accuracy: 0.9383\n",
      "Epoch 41/50\n",
      "208/208 [==============================] - 66s 317ms/step - loss: 0.2473 - accuracy: 0.9827 - val_loss: 1.2342 - val_accuracy: 0.9364\n",
      "Epoch 42/50\n",
      "208/208 [==============================] - 69s 332ms/step - loss: 0.0803 - accuracy: 0.9933 - val_loss: 1.5537 - val_accuracy: 0.9152\n",
      "Epoch 43/50\n",
      "208/208 [==============================] - 62s 297ms/step - loss: 0.0735 - accuracy: 0.9913 - val_loss: 1.1471 - val_accuracy: 0.9326\n",
      "Epoch 44/50\n",
      "208/208 [==============================] - 65s 314ms/step - loss: 0.0598 - accuracy: 0.9947 - val_loss: 2.0099 - val_accuracy: 0.9326\n",
      "Epoch 45/50\n",
      "208/208 [==============================] - 70s 335ms/step - loss: 0.2345 - accuracy: 0.9865 - val_loss: 1.3442 - val_accuracy: 0.9441\n",
      "Epoch 46/50\n",
      "208/208 [==============================] - 60s 290ms/step - loss: 0.2751 - accuracy: 0.9831 - val_loss: 1.5456 - val_accuracy: 0.9249\n",
      "Epoch 47/50\n",
      "208/208 [==============================] - 62s 297ms/step - loss: 0.2282 - accuracy: 0.9855 - val_loss: 1.4089 - val_accuracy: 0.9326\n",
      "Epoch 48/50\n",
      "208/208 [==============================] - 74s 355ms/step - loss: 0.1349 - accuracy: 0.9928 - val_loss: 2.0517 - val_accuracy: 0.9037\n",
      "Epoch 49/50\n",
      "208/208 [==============================] - 68s 327ms/step - loss: 0.1136 - accuracy: 0.9884 - val_loss: 1.0975 - val_accuracy: 0.9499\n",
      "Epoch 50/50\n",
      "208/208 [==============================] - 60s 290ms/step - loss: 0.2116 - accuracy: 0.9836 - val_loss: 1.5024 - val_accuracy: 0.9345\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, epochs = 50, batch_size = 10, verbose = 1,validation_data = (x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2abbd70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 9s 530ms/step - loss: 1.5024 - accuracy: 0.9345\n"
     ]
    }
   ],
   "source": [
    "accur=model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6192ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce118d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(r\"C:\\Users\\Shreeyash Pandey\\Downloads\\archive (3)\\TestDataSet\\yes\\y22.jpg\", cv2.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00e3ff40",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.resize(128,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "03bfe6f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5c5a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27f804e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "66a0fcfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]],\n",
       "\n",
       "       [[0],\n",
       "        [0],\n",
       "        [0],\n",
       "        ...,\n",
       "        [0],\n",
       "        [0],\n",
       "        [0]]], dtype=uint8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.reshape(128,128,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90eff243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.5880755e-08 1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "img = image.load_img(r\"\", target_size=(128, 128))\n",
    "img = np.expand_dims(img, axis=0)\n",
    "result=model.predict(img)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "029d9113",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(result,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93acb6a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
